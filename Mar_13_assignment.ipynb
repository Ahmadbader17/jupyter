{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer 1\n",
    "\n",
    "#### ANOVA (Analysis of Variance) is a statistical method used to test the differences among means of two or more groups. ANOVA relies on several assumptions to be valid:\n",
    "\n",
    "1) Independence: The observations within each group must be independent of each other. That is, the data points in one group should not be related to the data points in another group.\n",
    "\n",
    "2) Normality: The data in each group must follow a normal distribution. This assumption is important because ANOVA is based on the normal distribution and assumes that the residuals (the differences between the observed values and the predicted values) are normally distributed.\n",
    "\n",
    "3) Homogeneity of variances: The variances of the groups should be equal. This assumption is known as homoscedasticity. When the variances are not equal, the ANOVA test may lead to incorrect conclusions about the significance of differences among the groups.\n",
    "\n",
    "#### Examples of violations that could impact the validity of the results include:\n",
    "\n",
    "1) Violation of independence assumption: In some cases, the data points in one group may be related to the data points in another group. For example, if the same participants are used in multiple groups, or if measurements are taken over time from the same individuals, this could lead to a violation of the independence assumption.\n",
    "\n",
    "2) Violation of normality assumption: If the data in each group is not normally distributed, ANOVA may not be appropriate. For example, if the data is skewed or has outliers, this could impact the normality assumption.\n",
    "\n",
    "3) Violation of homogeneity of variances assumption: When the variances of the groups are not equal, this can lead to a violation of the homogeneity of variances assumption. For example, if one group has a larger variance than another group, this could lead to incorrect conclusions about the significance of differences among the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer 2\n",
    "\n",
    "1) One-way ANOVA: It is used to compare the means of two or more independent groups on a single continuous dependent variable. For example, to compare the average scores of students from different schools on a standardized test.\n",
    "\n",
    "2) Two-way ANOVA: It is used to examine the effects of two independent categorical variables on a continuous dependent variable. For example, to compare the average salaries of employees based on their gender and experience level.\n",
    "\n",
    "3) Three-way ANOVA: It is used to examine the effects of three independent categorical variables on a continuous dependent variable. For example, to compare the average scores of students from different schools based on their gender, race, and socioeconomic status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer 3\n",
    "\n",
    "The partitioning of variance in ANOVA refers to the process of decomposing the total variation in a dependent variable into different sources of variation. These sources of variation include the variation due to the treatment or independent variable(s), the variation due to random error, and the variation due to the interaction between the treatment and other factors.\n",
    "\n",
    "Understanding the partitioning of variance is important because it allows us to determine how much of the variation in the dependent variable is due to the treatment and how much is due to other sources of variation. This information can help us to assess the significance of the treatment effect and to identify any confounding variables that may be affecting the results. Additionally, by understanding the partitioning of variance, we can determine the appropriate statistical test to use and make valid inferences about the population parameters based on the sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer 4\n",
    "\n",
    "To calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python, you can use the ols function from the statsmodels library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# load data into a pandas DataFrame\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# fit one-way ANOVA model\n",
    "model = ols('dependent_variable ~ independent_variable', data=df).fit()\n",
    "\n",
    "# calculate total sum of squares (SST)\n",
    "sst = ((df['dependent_variable'] - df['dependent_variable'].mean())**2).sum()\n",
    "\n",
    "# calculate explained sum of squares (SSE)\n",
    "sse = ((model.fittedvalues - df['dependent_variable'].mean())**2).sum()\n",
    "\n",
    "# calculate residual sum of squares (SSR)\n",
    "ssr = ((df['dependent_variable'] - model.fittedvalues)**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer 5\n",
    "\n",
    "To calculate the main effects and interaction effects in a two-way ANOVA using Python, you can use the ols function from the statsmodels library and include the interaction term in the formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# load data into a pandas DataFrame\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# fit two-way ANOVA model\n",
    "model = ols('dependent_variable ~ independent_variable_1 + independent_variable_2 + independent_variable_1*independent_variable_2', data=df).fit()\n",
    "\n",
    "# calculate main effect of independent_variable_1\n",
    "me_iv1 = model.params['independent_variable_1']\n",
    "\n",
    "# calculate main effect of independent_variable_2\n",
    "me_iv2 = model.params['independent_variable_2']\n",
    "\n",
    "# calculate interaction effect\n",
    "ie = model.params['independent_variable_1:independent_variable_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer 6\n",
    "\n",
    "If you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02, you can conclude that there is a statistically significant difference between the groups. The F-statistic tells you the ratio of the variance between groups to the variance within groups. A large F-statistic means that the variation between groups is much larger than the variation within groups, which suggests that the means of the groups are different. The p-value tells you the probability of obtaining the observed F-statistic or a more extreme value if there is no difference between the groups. A p-value of 0.02 means that there is only a 2% chance of obtaining the observed F-statistic if there is no difference between the groups.\n",
    "\n",
    "Interpreting these results, you can say that the null hypothesis (i.e., there is no difference between the groups) can be rejected, and there is evidence of a significant difference between the groups. However, you cannot determine which specific groups are different from each other based on the ANOVA alone. You would need to perform post-hoc tests, such as Tukey's HSD or Bonferroni correction, to identify which groups differ significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asnwer 7\n",
    "\n",
    "In a repeated measures ANOVA, missing data can be handled using various methods, including listwise deletion, pairwise deletion, and imputation. Listwise deletion involves removing any cases that have missing data on any variable in the analysis. Pairwise deletion involves using all available data for each test, but can result in different sample sizes for different tests. Imputation involves estimating the missing values using statistical methods, such as mean imputation, regression imputation, or multiple imputation.\n",
    "\n",
    "The potential consequences of using different methods to handle missing data in repeated measures ANOVA can vary. Listwise deletion can result in biased estimates if the missing data are not missing at random. Pairwise deletion can reduce the power of the analysis and also result in biased estimates if the missing data are not missing at random. Imputation can introduce bias if the imputation model is misspecified or if the missing data are not missing at random. Thus, it is important to carefully consider the reasons for missing data and choose an appropriate method to handle the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer 8\n",
    "\n",
    "Some common post-hoc tests used after ANOVA include Tukey's Honestly Significant Difference (HSD), Bonferroni correction, and Scheffe's method. Tukey's HSD test is used to determine which pairs of groups are significantly different from each other. Bonferroni correction is used to adjust the p-values for multiple comparisons, and it is more conservative than Tukey's HSD test. Scheffe's method is a more conservative approach that controls the family-wise error rate.\n",
    "\n",
    "A post-hoc test might be necessary when a significant difference is found in the ANOVA and the researcher wants to determine which specific groups differ significantly from each other. For example, in a study comparing the effectiveness of three different treatments for a medical condition, a one-way ANOVA might show a significant difference between the treatments. A post-hoc test, such as Tukey's HSD or Bonferroni correction, could then be used to determine which specific treatments are significantly different from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer 9\n",
    "\n",
    "Here is an example of how to conduct a one-way ANOVA in Python for the researcher comparing the mean weight loss of three diets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# create dataframe with weight loss data\n",
    "df = pd.DataFrame({'diet': ['A']*50 + ['B']*50 + ['C']*50,\n",
    "                   'weight_loss': [1.2, 0.9, 1.5, 1.8, 2.2, ...]}) # insert the actual data\n",
    "\n",
    "# conduct one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(df[df['diet']=='A']['weight_loss'],\n",
    "                                      df[df['diet']=='B']['weight_loss'],\n",
    "                                      df[df['diet']=='C']['weight_loss'])\n",
    "\n",
    "print(\"F-statistic: \", f_statistic)\n",
    "print(\"p-value: \", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output will be the F-statistic and p-value for the ANOVA.\n",
    "\n",
    "Interpretation: If the p-value is less than the chosen alpha level (usually 0.05), then there is evidence to reject the null hypothesis and conclude that there is a significant difference between the mean weight loss of at least two of the diets. The F-statistic indicates the magnitude of the difference between the groups relative to the variability within the groups. A larger F-statistic indicates a larger difference between the groups relative to the variability within the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer 10\n",
    "\n",
    "Here is an example of how to conduct a two-way ANOVA in Python for the company comparing the average time to complete a task using three different software programs and two different employee experience levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# create dataframe with task completion time data\n",
    "df = pd.DataFrame({'program': ['A']*20 + ['B']*20 + ['C']*20,\n",
    "                   'experience': ['novice']*30 + ['experienced']*30,\n",
    "                   'time': [24.1, 22.5, 23.2, 26.8, 25.6, ...]}) # insert the actual data\n",
    "\n",
    "# conduct two-way ANOVA\n",
    "model = ols('time ~ C(program) + C(experience) + C(program):C(experience)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output will be an ANOVA table with F-statistics and p-values for the main effects of program and experience, as well as the interaction effect between program and experience.\n",
    "\n",
    "Interpretation: If the p-value for the main effect of program or experience is less than the chosen alpha level (usually 0.05), then there is evidence to reject the null hypothesis and conclude that there is a significant difference in task completion time based on that variable. If the p-value for the interaction effect is less than the chosen alpha level, then there is evidence to reject the null hypothesis and conclude that the effect of program on task completion time depends on employee experience level, or vice versa. The F-statistics indicate the magnitude of the differences relative to the variability within the groups. A larger F-statistic indicates a larger difference between the groups relative to the variability within the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# create a DataFrame to store the data\n",
    "data = pd.DataFrame({\n",
    "    'group': ['control', 'experimental'],\n",
    "    'score': [80, 85] # mean test scores for each group\n",
    "})\n",
    "\n",
    "# separate the two groups into arrays\n",
    "control = data.loc[data['group'] == 'control', 'score']\n",
    "experimental = data.loc[data['group'] == 'experimental', 'score']\n",
    "\n",
    "# conduct the two-sample t-test\n",
    "t_stat, p_val = stats.ttest_ind(control, experimental)\n",
    "\n",
    "# report the results\n",
    "print(f\"t-statistic: {t_stat:.2f}\")\n",
    "print(f\"p-value: {p_val:.4f}\")\n",
    "\n",
    "# conduct post-hoc test (Tukey's HSD)\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "mc = MultiComparison(data['score'], data['group'])\n",
    "result = mc.tukeyhsd()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output will show the t-statistic, p-value, and post-hoc test results. If the p-value is less than the significance level (e.g., 0.05), we can conclude that there is a significant difference in test scores between the control and experimental groups. The post-hoc test can then be used to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer 12\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "# create a DataFrame to store the data\n",
    "data = pd.DataFrame({\n",
    "    'day': ['day1']*3 + ['day2']*3 + ['day3']*3,\n",
    "    'store': ['storeA', 'storeB', 'storeC']*3,\n",
    "    'sales': [100, 120, 130, 80, 90, 100, 150, 140, 130]\n",
    "})\n",
    "\n",
    "# conduct the repeated measures ANOVA\n",
    "rm = AnovaRM(data, 'sales', 'store', within=['day'])\n",
    "result = rm.fit()\n",
    "\n",
    "# report the results\n",
    "print(result)\n",
    "\n",
    "# conduct post-hoc test (Tukey's HSD)\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "mc = MultiComparison(data['sales'], data[['day', 'store']])\n",
    "result = mc.tukeyhsd()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output will show the results of the repeated measures ANOVA and the post-hoc test. If the p-value for the main effect of store is less than the significance level (e.g., 0.05), we can conclude that there is a significant difference in sales between the three stores. The post-hoc test can then be used to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
