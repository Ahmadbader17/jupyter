{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c40ec4aa-1104-492d-b107-bd3c8958776f",
   "metadata": {},
   "source": [
    "# Answer 1\n",
    "\n",
    "The Filter method is a feature selection technique that evaluates the relevance of each feature independently of the target variable. It works by assigning a score to each feature based on a statistical metric, such as correlation or mutual information. Then, it selects the top K features with the highest scores and removes the rest. The main advantage of the Filter method is its computational efficiency, as it doesn't require training a model. However, it doesn't consider the interaction between features and may select irrelevant features that are highly correlated with the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a339d049-43f1-47d4-a4ac-0ec6cd4aab0b",
   "metadata": {},
   "source": [
    "# Answer 2\n",
    "\n",
    "The Wrapper method is a feature selection technique that evaluates subsets of features using a specific machine learning algorithm. It works by selecting a subset of features, training a model, and evaluating its performance. Then, it iteratively selects and evaluates different subsets of features until it finds the optimal set that maximizes the performance metric. The Wrapper method considers the interaction between features and can select the most relevant ones for a specific algorithm. However, it can be computationally expensive and prone to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17841215-1a28-4610-b305-f98367b7cdf4",
   "metadata": {},
   "source": [
    "# Answer 3\n",
    "\n",
    "Embedded feature selection methods are techniques that perform feature selection during the model training process. Some common techniques include:\n",
    "\n",
    "Lasso regression: it adds a penalty term to the linear regression cost function that encourages sparse solutions and automatically selects the most relevant features.\n",
    "\n",
    "Ridge regression: it adds a penalty term to the linear regression cost function that shrinks the coefficients of less relevant features towards zero, effectively reducing their impact on the model.\n",
    "\n",
    "Decision tree-based methods: decision trees can be used to select features by splitting the data based on their relevance to the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdb73dc-492a-4fa9-bb73-351c66bdc3cf",
   "metadata": {},
   "source": [
    "# Answer 4\n",
    "\n",
    "The Filter method has some drawbacks, including:\n",
    "\n",
    "It doesn't consider the interaction between features, which can lead to selecting irrelevant features that are highly correlated with the target variable.\n",
    "\n",
    "It may not select the optimal subset of features for a specific machine learning algorithm, as it doesn't take into account the model's complexity and capacity.\n",
    "\n",
    "It assumes that each feature is independent of the others, which may not always be the case in real-world scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53dad25-b622-4776-bdd9-415277fa119f",
   "metadata": {},
   "source": [
    "# Answer 5\n",
    "\n",
    "The Filter method is often preferred over the Wrapper method in situations where computational efficiency is a concern, and the model's performance is not sensitive to the selection of features. For example, if the dataset has a large number of features, and the algorithm used for modeling is relatively simple, such as linear regression or logistic regression, then the Filter method can be an appropriate choice. Additionally, the Filter method can be useful for exploratory data analysis, where the goal is to gain insights into the data before building a predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c9bab8-28f4-479e-a94b-b45a323881f1",
   "metadata": {},
   "source": [
    "# Answer 6\n",
    "\n",
    "To choose the most pertinent attributes for the model using the Filter method in a telecom company's customer churn project, follow the following steps:\n",
    "\n",
    "1) Identify the target variable: In this case, it is customer churn.\n",
    "\n",
    "2) Calculate the correlation between each feature and the target variable: Using correlation metrics such as Pearson's correlation or Spearman's rank correlation, calculate the correlation between each feature and the target variable.\n",
    "\n",
    "3) Rank the features based on their correlation: Sort the features based on their correlation with the target variable, in descending order.\n",
    "\n",
    "4) Select the top K features: Choose the top K features with the highest correlation scores, where K is determined based on the domain expertise or experimentation.\n",
    "\n",
    "5) Assess the selected features: Evaluate the performance of the predictive model using only the selected features, and compare it to the model's performance using all the features. If the model's performance is similar or better using only the selected features, then these features can be considered the most pertinent attributes for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b241fe9-f324-4fed-8616-231e1f7cb4ca",
   "metadata": {},
   "source": [
    "# Answer 7\n",
    "\n",
    "To use the Embedded method for feature selection in a soccer match outcome prediction project, follow these steps:\n",
    "\n",
    "1) Choose a machine learning algorithm: Choose a machine learning algorithm that supports embedded feature selection, such as Lasso regression or Ridge regression.\n",
    "\n",
    "2) Split the data into training and testing sets: Split the data into training and testing sets to prevent overfitting and assess the model's performance.\n",
    "\n",
    "3) Train the model with all the features: Train the machine learning algorithm with all the available features.\n",
    "\n",
    "4) Assess the feature importance: Assess the importance of each feature by examining its coefficient value or its weight in the model.\n",
    "\n",
    "5) Rank the features based on their importance: Rank the features based on their importance, in descending order.\n",
    "\n",
    "6) Remove the least important features: Remove the least important features, and retrain the model with the remaining features.\n",
    "\n",
    "7) Evaluate the model's performance: Evaluate the model's performance using the testing set, and repeat steps 4 to 7 until the desired level of performance is achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8080afc5-93ca-49e1-9f33-3d75d5f39e57",
   "metadata": {},
   "source": [
    "# Answer 8\n",
    "\n",
    "To use the Wrapper method for feature selection in a house price prediction project, follow these steps:\n",
    "\n",
    "1) Define a subset of features: Define a subset of features that are potentially relevant for predicting the house price.\n",
    "\n",
    "2) Split the data into training and testing sets: Split the data into training and testing sets to prevent overfitting and assess the model's performance.\n",
    "\n",
    "3) Train a model with the selected features: Train a machine learning algorithm with the selected subset of features.\n",
    "\n",
    "4) Evaluate the model's performance: Evaluate the model's performance using the testing set.\n",
    "\n",
    "5) Add or remove features: Add or remove features from the subset of selected features based on their impact on the model's performance. Repeat steps 3 to 5 until the desired level of performance is achieved.\n",
    "\n",
    "6) Validate the model's performance: Validate the model's performance using cross-validation or hold-out validation to ensure that it is not overfitting the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616b8add-bd4b-4c41-9184-aa4e44d5fb83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
