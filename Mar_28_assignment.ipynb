{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "415a0fdf-dfc0-4d26-a126-135ca6fd0dd0",
   "metadata": {},
   "source": [
    "# Answer 1\n",
    "\n",
    "Ridge Regression is a linear regression technique that introduces a regularization term in the objective function of the ordinary least squares (OLS) regression. This regularization term, also known as the L2 penalty, adds a constraint on the sum of the squared coefficients. The primary goal of this technique is to prevent overfitting by shrinking the coefficients of the model towards zero. Ridge Regression differs from OLS regression in the sense that it not only minimizes the residual sum of squares but also adds a regularization term to the objective function, which imposes a constraint on the size of the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a865e475-1dff-4aa1-b415-eb4b9fef1d16",
   "metadata": {},
   "source": [
    "# Answer 2\n",
    "\n",
    "The assumptions of Ridge Regression are similar to those of OLS regression. These assumptions include linearity, independence of errors, normality of errors, homoscedasticity, and absence of multicollinearity. However, Ridge Regression relaxes the assumption of absence of multicollinearity to some extent by introducing a regularization term, which can handle the situation where the independent variables are highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467ffa69-4992-42af-84d5-b76fe2344001",
   "metadata": {},
   "source": [
    "# Answer 3\n",
    "\n",
    "The tuning parameter (lambda) in Ridge Regression controls the strength of the regularization. A smaller value of lambda corresponds to less regularization, and a larger value of lambda corresponds to more regularization. The value of lambda can be selected using techniques such as cross-validation or generalized cross-validation, which involve testing different values of lambda and selecting the one that gives the best performance on a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed231d86-df7b-435d-b69e-06893e0495c1",
   "metadata": {},
   "source": [
    "# Answer 4\n",
    "\n",
    "Yes, Ridge Regression can be used for feature selection by shrinking the coefficients of less important variables towards zero. The variables with non-zero coefficients are considered important and selected as features. The strength of regularization, controlled by the tuning parameter lambda, determines the extent of shrinkage. A larger value of lambda will lead to more coefficients being shrunk to zero, resulting in a smaller set of selected features. In this way, Ridge Regression can be used for both regularization and feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07dc164-e255-4d6e-9c4c-2db0e3f52493",
   "metadata": {},
   "source": [
    "# Answer 5\n",
    "\n",
    "Ridge Regression is robust to the presence of multicollinearity, which is a situation where the independent variables are highly correlated. This is because the regularization term in Ridge Regression shrinks the coefficients of the correlated variables towards zero, reducing their impact on the model. This helps to reduce the variance of the estimates and improve the stability of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f5930d-926e-4927-9559-4011aa4434c5",
   "metadata": {},
   "source": [
    "# Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a202aa74-2dc2-4355-88df-3563508e11a6",
   "metadata": {},
   "source": [
    "# Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54417ab2-0533-45bc-945a-33b77add4c1e",
   "metadata": {},
   "source": [
    "# Answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
