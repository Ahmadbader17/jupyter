{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f29e73-9a0c-427a-aad0-435936f45acb",
   "metadata": {},
   "source": [
    "## Understanding pooling and padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fba9312-472b-4b5a-91e4-a3295ebcd500",
   "metadata": {},
   "source": [
    "### Answer 1\n",
    "\n",
    "Pooling in CNN (Convolutional Neural Network):\n",
    "\n",
    "Purpose: Pooling is a downsampling operation used in CNNs to reduce the spatial dimensions of the input feature maps while retaining important information. The primary purpose of pooling is to reduce the computational complexity of the model and to create a more abstracted representation of the input data. Pooling helps in capturing the dominant features of an image while making the network less sensitive to small spatial variations, translations, and distortions.\n",
    "\n",
    "Benefits:\n",
    "\n",
    "Dimensionality reduction: Pooling reduces the spatial dimensions of the feature maps, making subsequent layers computationally more efficient.\n",
    "Translation invariance: Pooling helps achieve a degree of spatial invariance by identifying the most prominent features regardless of their exact location in the input.\n",
    "Noise reduction: Pooling tends to reduce the impact of minor noise in the data by focusing on the most salient features.\n",
    "Feature generalization: By pooling, the network learns to identify more general patterns and less specific spatial details, which can improve the model's ability to generalize to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f29736-9428-472b-b4ce-bab64e11922c",
   "metadata": {},
   "source": [
    "### Answer 2\n",
    "\n",
    "Min Pooling vs. Max Pooling:\n",
    "\n",
    "Both min pooling and max pooling are types of pooling operations in CNNs, but they differ in how they aggregate information.\n",
    "\n",
    "Min Pooling: In min pooling, the operation takes the minimum value from the selected pool region. It is less commonly used than max pooling and is more sensitive to noise or outliers in the data. Min pooling might be used in specific cases where identifying the smallest value is meaningful, but it is not as popular as max pooling in most applications.\n",
    "\n",
    "Max Pooling: In max pooling, the operation takes the maximum value from the selected pool region. Max pooling is the most common type of pooling used in CNNs. It is more robust to noise or outliers compared to min pooling and helps to retain the most significant features in the feature map.\n",
    "\n",
    "In both min and max pooling, the pool region (also called the pooling window) slides over the feature map, and the operation is applied to non-overlapping or overlapping regions, depending on the settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0604d5a-9899-4034-9a7d-8ec3b1d2ed9d",
   "metadata": {},
   "source": [
    "### Answer 3\n",
    "\n",
    "Padding in CNN:\n",
    "\n",
    "In CNNs, padding refers to the process of adding extra pixels (usually zeros) to the borders of the input feature maps before applying the convolution operation. Padding is employed to control the spatial dimensions of the output feature maps after convolution and pooling operations.\n",
    "\n",
    "Significance:\n",
    "\n",
    "Preservation of spatial dimensions: Padding allows the output feature maps to have the same spatial dimensions as the input. Without padding, the spatial dimensions would decrease as the convolutional layers progress, leading to significant loss of spatial information.\n",
    "Border information retention: Padding ensures that the convolutional kernels can process the pixels at the borders of the input feature map, which would be otherwise underrepresented due to the sliding nature of the convolution operation.\n",
    "Mitigation of information loss: Padding helps in mitigating the information loss that occurs during the convolution operation, as the output size of the feature map depends on the size of the convolutional kernel and stride."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab25b7f-d4b1-420d-8874-dc470416912d",
   "metadata": {},
   "source": [
    "### Answer 4\n",
    "\n",
    "Zero-padding vs. Valid-padding:\n",
    "\n",
    "Zero-padding:\n",
    "\n",
    "In zero-padding, extra rows and columns of zeros are added around the borders of the input feature map before applying the convolution operation.\n",
    "The purpose of zero-padding is to preserve the spatial dimensions of the input feature map in the output feature map.\n",
    "Zero-padding increases the size of the feature map, and thus, it can help in maintaining more spatial information.\n",
    "It is commonly used when the goal is to maintain the spatial resolution, especially in the early layers of the CNN.\n",
    "Valid-padding:\n",
    "\n",
    "In valid-padding, no padding is applied, and the convolution operation is only applied to positions where the kernel fully overlaps with the input feature map.\n",
    "The valid-padding does not preserve the spatial dimensions of the input feature map in the output feature map.\n",
    "Valid-padding results in a smaller output feature map compared to the input feature map because the convolution is not applied at the borders.\n",
    "It is commonly used when the spatial resolution reduction is intended, as it helps in reducing computational complexity and is typically used in later layers of the CNN.\n",
    "In summary, zero-padding maintains spatial dimensions, while valid-padding leads to a reduction in feature map size. The choice of padding type depends on the specific requirements of the CNN architecture and the task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc921c20-497f-4413-b6b8-7d47787ed0a4",
   "metadata": {},
   "source": [
    "## Exploring LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbffcab8-2b11-461b-8cb8-3a2267b18e30",
   "metadata": {},
   "source": [
    "### Answer 1\n",
    "\n",
    "Brief Overview of LeNet-5 Architecture:\n",
    "LeNet-5 is a pioneering convolutional neural network (CNN) architecture developed by Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner in 1998. It was designed for handwritten digit recognition tasks, specifically recognizing characters in check reading machines. LeNet-5 played a crucial role in popularizing deep learning and laid the foundation for modern CNN architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca38f2-9bd1-4c90-9347-91deaf05f2fb",
   "metadata": {},
   "source": [
    "### Answer 2\n",
    "\n",
    "Key Components of LeNet-5 and Their Purposes:\n",
    "LeNet-5 consists of several key components, each serving a specific purpose:\n",
    "\n",
    "Input Layer: The network takes grayscale images of size 32x32 pixels as input.\n",
    "\n",
    "Convolutional Layers: LeNet-5 has two convolutional layers:\n",
    "\n",
    "The first convolutional layer applies six filters of size 5x5, with a stride of 1, and uses the tanh activation function.\n",
    "The second convolutional layer applies 16 filters of size 5x5, with a stride of 1, and also uses the tanh activation function. These layers extract features from the input images.\n",
    "Average Pooling Layers: After each convolutional layer, there is a subsampling layer (average pooling) that reduces the spatial dimensions while preserving important features. LeNet-5 uses average pooling of size 2x2 with a stride of 2.\n",
    "\n",
    "Fully Connected Layers: Following the convolutional and pooling layers, there are three fully connected layers:\n",
    "\n",
    "The first fully connected layer has 120 neurons and uses the tanh activation function.\n",
    "The second fully connected layer has 84 neurons and uses the tanh activation function.\n",
    "The third fully connected layer serves as the output layer with 10 neurons (corresponding to the 10 possible digit classes) and uses the softmax activation function to produce class probabilities.\n",
    "Flattening: Before passing the output of the last pooling layer to the fully connected layers, the data is flattened into a 1D vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9806504a-a68b-47e4-9ba7-36f11e5bc174",
   "metadata": {},
   "source": [
    "### Answer 3\n",
    "\n",
    "Advantages and Limitations of LeNet-5:\n",
    "Advantages:\n",
    "\n",
    "LeNet-5 was one of the first successful CNN architectures, demonstrating the effectiveness of deep learning for image recognition tasks.\n",
    "It introduced the concept of weight sharing in convolutional layers, reducing the number of parameters and enabling better generalization.\n",
    "The architecture is relatively simple and computationally efficient compared to modern deep networks.\n",
    "Limitations:\n",
    "\n",
    "LeNet-5 is designed for small, grayscale images (32x32 pixels), limiting its application to larger and more complex datasets.\n",
    "The tanh activation function used in LeNet-5 can suffer from vanishing gradients, which can slow down training.\n",
    "It may struggle with highly complex and diverse datasets compared to more advanced CNN architectures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea22760c-c8f5-4308-9cdd-25b7c19fd97a",
   "metadata": {},
   "source": [
    "### Answer 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74105230-6001-436f-ac79-8c044fd7cf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values to the range [0, 1]\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "# Expand dimensions to match LeNet-5 input size (32x32)\n",
    "train_images = tf.expand_dims(train_images, axis=-1)\n",
    "test_images = tf.expand_dims(test_images, axis=-1)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "train_labels = to_categorical(train_labels, num_classes=10)\n",
    "test_labels = to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "# Define the LeNet-5 model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(6, kernel_size=(5, 5), activation='tanh', input_shape=(32, 32, 1)))\n",
    "model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(layers.Conv2D(16, kernel_size=(5, 5), activation='tanh'))\n",
    "model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(120, activation='tanh'))\n",
    "model.add(layers.Dense(84, activation='tanh'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "model.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f934fe4-ef3d-445e-a4e1-6b034978d0d2",
   "metadata": {},
   "source": [
    "## Analyzing AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff9dc7d-a0e0-4018-a9ed-94ab9cc5ee80",
   "metadata": {},
   "source": [
    "### Answer 1\n",
    "\n",
    "AlexNet is a pioneering deep convolutional neural network (CNN) architecture that revolutionized the field of computer vision and played a significant role in popularizing deep learning. It was proposed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton in 2012 and won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in the same year, significantly outperforming traditional methods.\n",
    "\n",
    "Overview of the AlexNet architecture:\n",
    "\n",
    "Input Layer:\n",
    "AlexNet takes an RGB image as input with a fixed size of 224x224 pixels.\n",
    "\n",
    "Convolutional Layers:\n",
    "AlexNet consists of five convolutional layers, where each layer uses a bank of learnable filters (kernels) to extract hierarchical features from the input image. The filters slide across the image, performing element-wise multiplication and summing up the values to create feature maps.\n",
    "\n",
    "Activation Function:\n",
    "After each convolutional layer, a Rectified Linear Unit (ReLU) activation function is applied element-wise to introduce non-linearity, making the model more expressive.\n",
    "\n",
    "Pooling Layers:\n",
    "Between some convolutional layers, max-pooling layers are used to downsample the spatial dimensions of the feature maps. This reduces the computational complexity and helps make the network translation-invariant.\n",
    "\n",
    "Local Response Normalization (LRN):\n",
    "After some of the convolutional layers, Local Response Normalization (LRN) is applied to the feature maps. It helps increase the contrast of the feature maps and enhances generalization.\n",
    "\n",
    "Fully Connected Layers:\n",
    "AlexNet has three fully connected layers, also known as dense layers. The last fully connected layer produces the final classification scores.\n",
    "\n",
    "Dropout:\n",
    "To prevent overfitting, dropout is applied to the first two fully connected layers. Dropout randomly sets a fraction of the neuron activations to zero during training, forcing the network to be more robust and less reliant on specific neurons.\n",
    "\n",
    "Output Layer:\n",
    "The output layer uses the Softmax activation function to convert the final layer's raw scores into probabilities. These probabilities represent the likelihood of the input image belonging to different classes.\n",
    "\n",
    "Training:\n",
    "AlexNet is trained using stochastic gradient descent (SGD) with momentum. The authors also utilized data augmentation techniques, such as random cropping and horizontal flipping, to increase the effective size of the training dataset.\n",
    "\n",
    "Key Contributions and Impact:\n",
    "\n",
    "AlexNet was the first deep CNN to demonstrate superior performance on the ILSVRC 2012 competition, achieving a top-5 error rate of around 16.4% (the previous best was around 25%).\n",
    "The architecture popularized the use of deep learning in computer vision tasks and inspired the development of deeper and more sophisticated CNNs.\n",
    "The success of AlexNet encouraged further research in deep learning and triggered the deep learning revolution, leading to significant advancements in various fields of artificial intelligence.\n",
    "Since the introduction of AlexNet, there have been many architectural improvements and variants of CNNs, but it remains a crucial milestone in the history of deep learning and image recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10607e9b-f0dd-4691-8e02-a3a3c909071b",
   "metadata": {},
   "source": [
    "### Answer 2\n",
    "\n",
    "\n",
    "AlexNet, introduced in 2012, marked a significant milestone in the field of computer vision and deep learning. The architectural innovations in AlexNet that contributed to its breakthrough performance are as follows:\n",
    "\n",
    "Deep Architecture: AlexNet was one of the first CNNs to employ a deep architecture with multiple layers. It consisted of eight layers, including five convolutional layers and three fully connected layers. Prior to AlexNet, most CNNs were relatively shallow, often limited to just a few layers. The increased depth allowed the model to learn hierarchical and complex features from the input data, enabling it to capture intricate patterns and representations.\n",
    "\n",
    "Convolutional Layers with Large Kernels: AlexNet used large-sized convolutional kernels compared to previous networks. Specifically, the first convolutional layer used a 11x11 filter, and the subsequent layers used 5x5 filters. Using larger kernels allowed the model to capture more extensive spatial information in the early layers, thereby recognizing broader features in the input images.\n",
    "\n",
    "Rectified Linear Units (ReLU) Activation: AlexNet introduced the use of Rectified Linear Units as activation functions after each convolutional and fully connected layer. ReLUs are computationally efficient and address the vanishing gradient problem more effectively than traditional activation functions like sigmoid or tanh. This non-linearity allowed the network to learn complex relationships within the data more efficiently.\n",
    "\n",
    "Overlapping Max-Pooling: The pooling layers in AlexNet employed a max-pooling operation with a relatively large pool size (e.g., 3x3) and a stride smaller than the pool size (e.g., 2). Moreover, the pooling regions were overlapping, meaning that the pool windows shared common elements. Overlapping pooling helped retain more spatial information compared to non-overlapping pooling and contributed to better feature localization.\n",
    "\n",
    "Local Response Normalization (LRN): In the earlier layers of AlexNet, local response normalization (LRN) was applied after ReLU activations. LRN normalizes the responses of neurons across nearby channels, which encourages competition among different features and enhances the model's generalization ability.\n",
    "\n",
    "Data Augmentation and Dropout: AlexNet employed data augmentation techniques during training to increase the effective size of the training set. Techniques like flipping, cropping, and color jittering were used to expose the network to various transformations of the input data, reducing overfitting. Additionally, dropout was used in the fully connected layers, randomly dropping out some neurons during training to prevent co-adaptation and enhance the model's robustness.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb7f3f0-f234-4d97-890e-134ae29d6cdb",
   "metadata": {},
   "source": [
    "### Answer 3\n",
    "\n",
    "In AlexNet, each type of layer plays a crucial role in the overall architecture, contributing to its ability to learn and recognize complex patterns in images. Let's discuss the role of convolutional layers, pooling layers, and fully connected layers in AlexNet:\n",
    "\n",
    "Convolutional Layers:\n",
    "Convolutional layers are the building blocks of convolutional neural networks (CNNs) and serve as feature extractors in AlexNet. The role of convolutional layers in AlexNet is to learn local patterns and feature representations from the input images. They do this by applying a set of learnable filters (also called kernels) to the input data.\n",
    "In AlexNet, the first layer uses a large 11x11 convolutional filter, and subsequent layers use smaller 3x3 and 5x5 filters. The depth of the feature maps increases with the depth of the convolutional layers. This design allows the network to learn low-level features like edges and textures in the early layers and gradually learn higher-level features and complex representations as the layers become deeper. Each convolutional layer performs a convolution operation, followed by an activation function (ReLU in the case of AlexNet), which introduces non-linearity.\n",
    "\n",
    "Pooling Layers:\n",
    "Pooling layers, specifically max-pooling in the case of AlexNet, are employed to reduce the spatial dimensions of the feature maps while retaining important information. The role of pooling layers in AlexNet is twofold:\n",
    "a. Dimension Reduction: Pooling layers decrease the spatial resolution of the feature maps, effectively down-sampling the data. This reduces the computational complexity of the network, making it computationally more efficient.\n",
    "\n",
    "b. Translation Invariance: Pooling introduces a degree of translation invariance to the learned features. By selecting the maximum value within a pooling region (e.g., 3x3 window), the network becomes less sensitive to slight shifts in the position of the detected features. This allows the network to recognize features in slightly different positions within an image.\n",
    "\n",
    "In AlexNet, the pooling layers use a relatively large pool size (e.g., 3x3) and a smaller stride (e.g., 2), meaning that the pooling regions overlap. This overlapping pooling strategy helps to preserve more spatial information and contributes to better feature localization.\n",
    "\n",
    "Fully Connected Layers:\n",
    "The fully connected layers in AlexNet are located at the end of the network and are responsible for making the final predictions based on the high-level features learned by the convolutional and pooling layers. The role of fully connected layers is to perform traditional dense neural network operations.\n",
    "The last pooling layer's output is flattened into a one-dimensional vector, which serves as the input to the first fully connected layer. The subsequent fully connected layers transform the data through a series of weight matrices and activation functions. In AlexNet, ReLU activation functions are used after each fully connected layer. The final fully connected layer typically outputs probabilities for different classes in the classification task, and the class with the highest probability is chosen as the predicted label.\n",
    "\n",
    "In summary, convolutional layers learn local patterns and features from the input images, pooling layers reduce spatial dimensions and introduce translation invariance, and fully connected layers perform high-level feature processing and produce the final predictions. The combination of these layer types and their architectural innovations made AlexNet highly effective in image classification tasks and sparked the advancement of deep learning in computer vision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0c36d7-449d-41f2-89da-64cbc4c1638e",
   "metadata": {},
   "source": [
    "### Answer 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6f863f-f57c-46d2-a228-035b021e34ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, datasets, utils\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize the pixel values to be in the range [0, 1]\n",
    "x_train, x_test = x_train.astype('float32') / 255.0, x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Define the AlexNet model\n",
    "def alexnet_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Convolutional layers\n",
    "    model.add(layers.Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Conv2D(256, kernel_size=(5, 5), padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Fully connected layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Create and compile the model\n",
    "model = alexnet_model(input_shape, num_classes=10)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model on the CIFAR-10 dataset\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]}')\n",
    "print(f'Test accuracy: {score[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
